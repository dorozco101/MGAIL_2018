{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/higgsfield/RL-Adventure-2\n",
    "\n",
    "#modified to store qpos and qvel in buffer all_trajectories and pickles them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalize action space</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "\n",
    "    def _action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = low_bound + (action + 1.0) * 0.5 * (upper_bound - low_bound)\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low_bound) / (upper_bound - low_bound) - 1\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ornstein-Uhlenbeck process</h2>\n",
    "Adding time-correlated noise to the actions taken by the deterministic policy<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process\">wiki</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise(object):\n",
    "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.3, min_sigma=0.3, decay_period=100000):\n",
    "        self.mu           = mu\n",
    "        self.theta        = theta\n",
    "        self.sigma        = max_sigma\n",
    "        self.max_sigma    = max_sigma\n",
    "        self.min_sigma    = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.action_dim   = action_space.shape[0]\n",
    "        self.low          = action_space.low\n",
    "        self.high         = action_space.high\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dim) * self.mu\n",
    "        \n",
    "    def evolve_state(self):\n",
    "        x  = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "    \n",
    "    def get_action(self, action, t=0):\n",
    "        ou_state = self.evolve_state()\n",
    "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
    "        return np.clip(action + ou_state, self.low, self.high)\n",
    "    \n",
    "#https://github.com/vitchyr/rlkit/blob/master/rlkit/exploration_strategies/ou_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Continuous control with deep reinforcement learning</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1509.02971\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.tanh(self.linear3(x))\n",
    "        return x\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state  = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        action = self.forward(state)\n",
    "        return action.detach().cpu().numpy()[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DDPG Update</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_update(batch_size, \n",
    "           gamma = 0.99,\n",
    "           min_value=-np.inf,\n",
    "           max_value=np.inf,\n",
    "           soft_tau=1e-2):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    policy_loss = value_net(state, policy_net(state))\n",
    "    policy_loss = -policy_loss.mean()\n",
    "\n",
    "    next_action    = target_policy_net(next_state)\n",
    "    target_value   = target_value_net(next_state, next_action.detach())\n",
    "    expected_value = reward + (1.0 - done) * gamma * target_value\n",
    "    expected_value = torch.clamp(expected_value, min_value, max_value)\n",
    "\n",
    "    value = value_net(state, action)\n",
    "    value_loss = value_criterion(value, expected_value.detach())\n",
    "\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-30 17:11:07,528] Making new env: InvertedPendulum-v1\n"
     ]
    }
   ],
   "source": [
    "env = NormalizedActions(gym.make(\"InvertedPendulum-v1\"))\n",
    "ou_noise = OUNoise(env.action_space)\n",
    "\n",
    "state_dim  = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "hidden_dim = 256\n",
    "\n",
    "value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "target_value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "target_policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "    \n",
    "value_lr  = 1e-3\n",
    "policy_lr = 1e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(),  lr=value_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames  = 12000\n",
    "max_steps   = 500\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "batch_size  = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(env.env.env.data.qpos.shape)\n",
    "print(env.env.env.data.qvel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajectories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e0b45fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d068b77c7e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_trajectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqpos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqvel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mddpg_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4f6240d040c4>\u001b[0m in \u001b[0;36mddpg_update\u001b[0;34m(batch_size, gamma, min_value, max_value, soft_tau)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mvalue_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3ee8c5e80610>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while frame_idx < max_frames:\n",
    "    state = env.reset()\n",
    "    ou_noise.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action = policy_net.get_action(state)\n",
    "        action = ou_noise.get_action(action, step)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        qpos,qvel = env.env.env.model.data.qpos.flatten(),env.env.env.model.data.qvel.flatten()\n",
    "        \n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "        all_trajectories.append((state, action, reward, next_state, done,qpos,qvel))\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            ddpg_update(batch_size)\n",
    "        \n",
    "        episode_reward += reward\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            plot(frame_idx, rewards)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    rewards.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "for step in all_trajectories:\n",
    "    step1 =[]\n",
    "    \n",
    "    state = step[0].tolist()\n",
    "    action = step[1].tolist()\n",
    "    reward = step[2]\n",
    "    nextState = step[3].tolist()\n",
    "    done = float(step[4])\n",
    "    qpos = step[5]\n",
    "    qvel = step[6]\n",
    "    step1.append(state)\n",
    "    step1.append(action)\n",
    "    step1.append(reward)\n",
    "    step1.append(nextState)\n",
    "    step1.append(done)\n",
    "    step1.append(qpos)\n",
    "    step1.append(qvel)\n",
    "    buffer.append(step1)\n",
    "    \n",
    "pickle.dump(buffer,open('states.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
