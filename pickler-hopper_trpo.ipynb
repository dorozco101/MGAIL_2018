{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate for trpo: we know the step numbers to begin and end at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "envName = 'Hopper-v1'\n",
    "#make sure we adjust the environment name because we dont want to overwrite!!!\n",
    "path = 'expert_pickles/'+envName+'.pickle'\n",
    "file = open(path,'rb')\n",
    "traj = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med\n",
    "\n",
    "start_step = 852181\n",
    "end_step = start_step + 50000\n",
    "\n",
    "traj_medium = traj[start_step:end_step]\n",
    "traj_med_zip = list(zip(*traj_medium))\n",
    "\n",
    "med_actions = traj_med_zip[1]\n",
    "med_rewards = traj_med_zip[2]\n",
    "med_nextStates = traj_med_zip[3]\n",
    "med_terminals = traj_med_zip[4]\n",
    "med_qpos = traj_med_zip[5]\n",
    "med_vel = traj_med_zip[6]\n",
    "\n",
    "np.save(envName+'_med_actions.npy',np.asarray(med_actions))\n",
    "np.save(envName+'_med_rewards.npy',np.asarray(med_rewards))\n",
    "np.save(envName+'_med_nextStates.npy',np.asarray(med_nextStates))\n",
    "np.save(envName+'_med_terminals.npy',np.asarray(med_terminals))\n",
    "np.save(envName+'_med_qpos.npy',np.asarray(med_qpos))\n",
    "np.save(envName+'_med_qvel.npy',np.asarray(med_qvel))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good\n",
    "\n",
    "start_step = 6721031\n",
    "end_step = start_step + 50000\n",
    "\n",
    "traj_good = traj[start_step:end_step]\n",
    "traj_good_zip = list(zip(*traj_good))\n",
    "\n",
    "good_actions = traj_good_zip[1]\n",
    "good_rewards = traj_good_zip[2]\n",
    "good_nextStates = traj_good_zip[3]\n",
    "good_terminals = traj_good_zip[4]\n",
    "good_qpos = traj_good_zip[5]\n",
    "good_vel = traj_good_zip[6]\n",
    "\n",
    "np.save(envName+'_good_actions.npy',np.asarray(good_actions))\n",
    "np.save(envName+'_good_rewards.npy',np.asarray(good_rewards))\n",
    "np.save(envName+'_good_nextStates.npy',np.asarray(good_nextStates))\n",
    "np.save(envName+'_good_terminals.npy',np.asarray(good_terminals))\n",
    "np.save(envName+'_good_qpos.npy',np.asarray(good_qpos))\n",
    "np.save(envName+'_good_qvel.npy',np.asarray(good_qvel))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed \n",
    "\n",
    "traj_mix_zip = traj_good_zip[:25000] + traj_good_zip[:25000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/ORIGINAL VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "envName = 'Hopper-v1'\n",
    "#make sure we adjust the environment name because we dont want to overwrite!!!\n",
    "path = 'expert_pickles/'+envName+'.pickle'\n",
    "file = open(path,'rb')\n",
    "traj = pickle.load(file)\n",
    "episodes = []\n",
    "states = []\n",
    "actions = []\n",
    "nextStates = []\n",
    "rewards = []\n",
    "terminals = []\n",
    "qpos=[]\n",
    "qvel=[]\n",
    "rewardCounter = 0\n",
    "\n",
    "#lowerLim = 10\n",
    "#upperLim = 30\n",
    "#upperLim2 = upperLim+10\n",
    "\n",
    "start_step = 852181\n",
    "end_step = start_step + 50000\n",
    "\n",
    "traj_medium = traj[start_step:end_step]\n",
    "traj_zip = list(zip(*traj_medium))\n",
    "\n",
    "med_actions = traj_zip[1]\n",
    "med_rewards = traj_zip[2]\n",
    "med_nextStates = traj_zip[3]\n",
    "med_terminals = traj_zip[4]\n",
    "med_qpos = traj_zip[5]\n",
    "med_vel = traj_zip[6]\n",
    "\n",
    "np.save(envName+'_med_actions.npy',np.asarray(med_actions))\n",
    "np.save(envName+'_med_rewards.npy',np.asarray(med_rewards))\n",
    "np.save(envName+'_med_nextStates.npy',np.asarray(med_nextStates))\n",
    "np.save(envName+'_med_terminals.npy',np.asarray(med_terminals))\n",
    "np.save(envName+'_med_qpos.npy',np.asarray(med_qpos))\n",
    "np.save(envName+'_med_qvel.npy',np.asarray(med_qvel))   \n",
    "\n",
    "#    \n",
    "for step in traj:\n",
    "    states.append(step[0])\n",
    "    actions.append(step[1])\n",
    "    reward = step[2]\n",
    "    rewards.append(reward)\n",
    "    nextStates.append(step[3])\n",
    "    done = step[4]\n",
    "    terminals.append(done)\n",
    "    qpos.append(step[5])\n",
    "    qvel.append(step[6])\n",
    "    rewardCounter += reward\n",
    "    if done:\n",
    "        episode=[]\n",
    "        episode.append(states)\n",
    "        episode.append(actions)\n",
    "        episode.append(rewards)\n",
    "        episode.append(nextStates)\n",
    "        episode.append(terminals)\n",
    "        episode.append(qpos)\n",
    "        episode.append(qvel)\n",
    "        episode.append(rewardCounter)\n",
    "        episodes.append(episode)\n",
    "        \n",
    "        #reset everything\n",
    "        states = []\n",
    "        actions = []\n",
    "        nextStates = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        qpos=[]\n",
    "        qvel=[]\n",
    "        rewardCounter = 0\n",
    "    \n",
    "episodes.sort(key=lambda x:x[7])\n",
    "\n",
    "ep_list = list(zip(*episodes))[7]\n",
    "#print(ep_list)\n",
    "counter = 0\n",
    "plt.hist(ep_list)\n",
    "counter = 0 \n",
    "good_indices = []\n",
    "bad_indices = []\n",
    "\n",
    "for index,ep in enumerate(ep_list):\n",
    "    if ep > upperLim:\n",
    "        good_indices.append(index)\n",
    "    if ep < upperLim2 and ep > lowerLim:\n",
    "        bad_indices.append(index)\n",
    "print(len(good_indices))\n",
    "print(len(bad_indices))   \n",
    "\n",
    "\n",
    "\n",
    "good_actions = []\n",
    "good_rewards = []\n",
    "good_terminals = []\n",
    "good_qpos = []\n",
    "good_qvel = []\n",
    "good_nextStates = []\n",
    "\n",
    "mixed_actions = []\n",
    "mixed_rewards = []\n",
    "mixed_terminals = []\n",
    "mixed_qpos = []\n",
    "mixed_qvel = []\n",
    "mixed_nextStates = []\n",
    "\n",
    "bad_actions = []\n",
    "bad_rewards = []\n",
    "bad_terminals = []\n",
    "bad_qpos = []\n",
    "bad_qvel = []\n",
    "bad_nextStates = []\n",
    "\n",
    "broke = False\n",
    "for index in reversed(good_indices):\n",
    "    currentEp = episodes[index]\n",
    "    good_actions = good_actions + currentEp[1]\n",
    "    good_rewards = good_rewards + currentEp[2]\n",
    "    good_nextStates = good_nextStates + currentEp[3]\n",
    "    good_terminals = good_terminals + currentEp[4]\n",
    "    good_qpos = good_qpos+currentEp[5]\n",
    "    good_qvel = good_qvel+currentEp[6]\n",
    "    \n",
    "    if len(good_actions) >= 50000:\n",
    "        print(\"'Good' thresh: Broken correctly\")\n",
    "        broke= True\n",
    "        break\n",
    "    if len(mixed_actions) >= 25000:\n",
    "        pass\n",
    "    else:\n",
    "        mixed_actions = mixed_actions + currentEp[1]\n",
    "        mixed_rewards = mixed_rewards + currentEp[2]\n",
    "        mixed_nextStates = mixed_nextStates + currentEp[3]\n",
    "        mixed_terminals = mixed_terminals + currentEp[4]\n",
    "        mixed_qpos = mixed_qpos+currentEp[5]\n",
    "        mixed_qvel = mixed_qvel+currentEp[6]\n",
    "if broke == False:\n",
    "    print(\"'Error: not enough data in range: change 'good' thresh\")\n",
    "                \n",
    "broke = False     \n",
    "for index in (bad_indices):\n",
    "    currentEp = episodes[index]\n",
    "    bad_actions = bad_actions + currentEp[1]\n",
    "    bad_rewards = bad_rewards + currentEp[2]\n",
    "    bad_nextStates = bad_nextStates + currentEp[3]\n",
    "    bad_terminals = bad_terminals + currentEp[4]\n",
    "    bad_qpos = bad_qpos+currentEp[5]\n",
    "    bad_qvel = bad_qvel+currentEp[6]\n",
    "    \n",
    "    if len(bad_actions) >= 50000:\n",
    "        print(\"'Bad' Thresh: Broken correctly\")\n",
    "        broke= True\n",
    "        break\n",
    "    if len(mixed_actions) >= 50000:\n",
    "        pass\n",
    "    else:\n",
    "        mixed_actions = mixed_actions + currentEp[1]\n",
    "        mixed_rewards = mixed_rewards + currentEp[2]\n",
    "        mixed_nextStates = mixed_nextStates + currentEp[3]\n",
    "        mixed_terminals = mixed_terminals + currentEp[4]\n",
    "        mixed_qpos = mixed_qpos+currentEp[5]\n",
    "        mixed_qvel = mixed_qvel+currentEp[6]\n",
    "if broke == False:\n",
    "    print(\"Error: not enough data in range: change 'bad' thresh\")\n",
    "\n",
    "\n",
    "good_actions=good_actions[:50000]\n",
    "good_rewards=good_rewards[:50000]\n",
    "good_nextStates=good_nextStates[:50000]\n",
    "good_terminals=good_terminals[:50000]\n",
    "good_qpos=good_qpos[:50000]\n",
    "good_qvel=good_qvel[:50000]\n",
    "good_terminals[-1]=1.0\n",
    "\n",
    "mixed_actions=mixed_actions[:50000]\n",
    "mixed_rewards=mixed_rewards[:50000]\n",
    "mixed_nextStates=mixed_nextStates[:50000]\n",
    "mixed_terminals=mixed_terminals[:50000]\n",
    "mixed_qpos=mixed_qpos[:50000]\n",
    "mixed_qvel=mixed_qvel[:50000]\n",
    "mixed_terminals[-1]=1.0\n",
    "\n",
    "bad_actions=bad_actions[:50000]\n",
    "bad_rewards=bad_rewards[:50000]\n",
    "bad_nextStates=bad_nextStates[:50000]\n",
    "bad_terminals=bad_terminals[:50000]\n",
    "bad_qpos=bad_qpos[:50000]\n",
    "bad_qvel=bad_qvel[:50000]\n",
    "bad_terminals[-1]=1.0\n",
    "\n",
    "envName = 'expert_numpys/'+envName \n",
    "\n",
    "np.save(envName+'_good_actions.npy',np.asarray(good_actions))\n",
    "np.save(envName+'_good_rewards.npy',np.asarray(good_rewards))\n",
    "np.save(envName+'_good_nextStates.npy',np.asarray(good_nextStates))\n",
    "np.save(envName+'_good_terminals.npy',np.asarray(good_terminals))\n",
    "np.save(envName+'_good_qpos.npy',np.asarray(good_qpos))\n",
    "np.save(envName+'_good_qvel.npy',np.asarray(good_qvel))\n",
    "\n",
    "np.save(envName+'_bad_actions.npy',np.asarray(bad_actions))\n",
    "np.save(envName+'_bad_rewards.npy',np.asarray(bad_rewards))\n",
    "np.save(envName+'_bad_nextStates.npy',np.asarray(bad_nextStates))\n",
    "np.save(envName+'_bad_terminals.npy',np.asarray(bad_terminals))\n",
    "np.save(envName+'_bad_qpos.npy',np.asarray(bad_qpos))\n",
    "np.save(envName+'_bad_qvel.npy',np.asarray(bad_qvel))\n",
    "\n",
    "np.save(envName+'_mixed_actions.npy',np.asarray(mixed_actions))\n",
    "np.save(envName+'_mixed_rewards.npy',np.asarray(mixed_rewards))\n",
    "np.save(envName+'_mixed_nextStates.npy',np.asarray(mixed_nextStates))\n",
    "np.save(envName+'_mixed_terminals.npy',np.asarray(mixed_terminals))\n",
    "np.save(envName+'_mixed_qpos.npy',np.asarray(mixed_qpos))\n",
    "np.save(envName+'_mixed_qvel.npy',np.asarray(mixed_qvel))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = '_mixed'\n",
    "actions = np.load(envName+sentiment+'_actions.npy')\n",
    "states = np.load(envName+sentiment+'_nextStates.npy')\n",
    "rewards = np.load(envName+sentiment+'_rewards.npy')\n",
    "qpos = np.load(envName+sentiment+'_qpos.npy')\n",
    "qvel = np.load(envName+sentiment+'_qvel.npy')\n",
    "terminals = np.load(envName+sentiment+'_terminals.npy')\n",
    "print(actions.shape)\n",
    "print(states.shape)\n",
    "print(rewards.shape)\n",
    "print(qpos.shape)\n",
    "print(qvel.shape)\n",
    "print(terminals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
